---
title: "Data607-Major Assignment-Project3-Most Valued Data Science Skills"
author: "Leo Yi / David Blumensteil / Manolis Manoli / Vinayak Kamath"
date: "3/11/2020"
output:
  ioslides_presentation:
    self_contained: true
    widescreen: true
    smaller: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(knitr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(scales)

#install.packages("wordcloud")
library("wordcloud")
#install.packages("RColorBrewer")
library("RColorBrewer")
library(maps)

stateFromLower <-function(x) {
   #read 52 state codes into local variable [includes DC (Washington D.C. and PR (Puerto Rico)]
  st.codes<-data.frame(
                      state=as.factor(c("AK", "AL", "AR", "AZ", "CA", "CO", "CT", "DC", "DE", "FL", "GA",
                                         "HI", "IA", "ID", "IL", "IN", "KS", "KY", "LA", "MA", "MD", "ME",
                                         "MI", "MN", "MO", "MS",  "MT", "NC", "ND", "NE", "NH", "NJ", "NM",
                                         "NV", "NY", "OH", "OK", "OR", "PA", "PR", "RI", "SC", "SD", "TN",
                                         "TX", "UT", "VA", "VT", "WA", "WI", "WV", "WY")),
                      full=as.factor(c("alaska","alabama","arkansas","arizona","california","colorado",
                                       "connecticut","district of columbia","delaware","florida","georgia",
                                       "hawaii","iowa","idaho","illinois","indiana","kansas","kentucky",
                                       "louisiana","massachusetts","maryland","maine","michigan","minnesota",
                                       "missouri","mississippi","montana","north carolina","north dakota",
                                       "nebraska","new hampshire","new jersey","new mexico","nevada",
                                       "new york","ohio","oklahoma","oregon","pennsylvania","puerto rico",
                                       "rhode island","south carolina","south dakota","tennessee","texas",
                                       "utah","virginia","vermont","washington","wisconsin",
                                       "west virginia","wyoming"))
                       )
     #create an nx1 data.frame of state codes from source column
  st.x<-data.frame(state=x)
     #match source codes with codes from 'st.codes' local variable and use to return the full state name
  refac.x<-st.codes$full[match(st.x$state,st.codes$state)]
     #return the full state names in the same order in which they appeared in the original source
  return(refac.x)
 
}

```



```{r, include = F}
## INPUT

#Loads the dataset
df_raw <- read.csv("https://raw.githubusercontent.com/davidblumenstiel/data/master/indeed_job_dataset.csv",stringsAsFactors = FALSE)

#Create working df object
df <- df_raw
```



## Soft Skills 

```{r, include = T}

#keywords as 'keywords'
keywords<-unname(unlist(read.csv("https://raw.githubusercontent.com/chilleundso/DATA607/master/Project3/softskills.csv", stringsAsFactors = FALSE)))

#Iniates new columns for each keyword; also makes list index list
df[keywords] <- NA
keywordColIndex <- seq(length(df)-length(keywords)+1,length(df),1)

#Will determine if contains keywords; occurs (1), or doesnt occur(0)
#Coerces multiple occurances to 1
i = 0
for (desc in df$Description) {
  i = i + 1
  df[i,keywordColIndex] <-(as.integer(str_detect(desc,fixed(keywords, ignore_case = TRUE))))
}

#Gets rid of the descriptions
df$Description <- NULL

#Gather soft skills
df2 <- df[,c(1, 44:ncol(df))] %>%
  gather(skill, flag, -X) %>%
  filter(flag == 1) %>%
  select(id = X, skill) %>%
  mutate(skill_type = 'soft')
```

```{r, include = F}
#Gather soft skills
df2 <- df[,c(1, 44:ncol(df))] %>%
  gather(skill, flag, -X) %>%
  filter(flag == 1) %>%
  select(id = X, skill) %>%
  mutate(skill_type = 'soft')
```

## Hard Skills

```{r, include = T}


# List all hard skills and how often they were listed in a separate dataframe
for (i in 1:nrow(df_raw)) {
  slist <- str_extract_all(df_raw$Skill[i], "'.+?'")
  temp_df <- data.frame(skill = slist[[1]])
  if (nrow(temp_df) > 0) {
    temp_df$id <- i - 1
    temp_df$skill <- as.character(temp_df$skill)
    temp_df <- select(temp_df, id, skill)
    if (i == 1) {
      sdf <- temp_df
    } else {
      sdf <- bind_rows(sdf, temp_df)
    }
  }
}

# Remove quotes and trim whitespace
sdf$skill <- str_replace_all(sdf$skill, "'", "")
sdf$skill <- str_replace_all(sdf$skill, '"', "")
sdf$skill <- str_trim(sdf$skill)
sdf$skill_type <- 'hard'

# Combine skills
skills <- bind_rows(df2, sdf)
```


## Job Title

```{r, warning = FALSE, include = T}
df <- df_raw
job.indeed.df  <- df %>%
  select(c(Id=X, (Job_Title)))

# Pattern Building:
pattern.analyst <- c('analyst','statistician','analysis','analytics')
pattern.engineer <- c('engineer', 'engg', 'technician','technologist','designer','architect')
pattern.scientist <- c('scientist','doctor','dr.')
pattern.junior <- c('junior','jr', 'entry','internship','jr.')
pattern.senior <- c('senior', 'sr','experienced','sr.')

# Intermedaite Data Frame for Titlles:
final.data.df <- data.frame(Id=integer(nrow(job.indeed.df)), Job_Title=character(nrow(job.indeed.df))
                            , analyst=integer(nrow(job.indeed.df)) ,engineer=integer(nrow(job.indeed.df)),scientist=integer(nrow(job.indeed.df))
                            , junior=integer(nrow(job.indeed.df)),senior=integer(nrow(job.indeed.df)))
final.data.df$Id <-   job.indeed.df$Id
final.data.df$Job_Title <- as.character( as.character( job.indeed.df$Job_Title) )

# Working on the counts:
for (i in 1: nrow(job.indeed.df)) {
  final.data.df$analyst[i] <- if(grepl(paste(pattern.analyst,collapse="|"), job.indeed.df$Job_Title[i], ignore.case = TRUE) )  1 else 0
  final.data.df$engineer[i] <- if(grepl(paste(pattern.engineer,collapse="|"), job.indeed.df$Job_Title[i], ignore.case = TRUE) )  1 else 0
  final.data.df$scientist[i] <- if(grepl(paste(pattern.scientist,collapse="|"), job.indeed.df$Job_Title[i], ignore.case = TRUE) )  1 else 0
  final.data.df$junior[i] <- if(grepl(paste(pattern.junior,collapse="|"), job.indeed.df$Job_Title[i], ignore.case = TRUE) )  1 else 0
  final.data.df$senior[i] <- if(grepl(paste(pattern.senior,collapse="|"), job.indeed.df$Job_Title[i], ignore.case = TRUE) )  1 else 0
}

```


```{r, include = F}
## DATA FOR HARD SKILLS VISUALIZATION

# Add job title flags to original dataframe
# Merging with main Analysis Data Frame:
df_all <- left_join(df_raw[,1:16], final.data.df[,-2], by = c('X' = 'Id'))
names(df_all)[1] <- 'job_id'




# hard skills dataframe for visualizations
hs <- filter(skills, skill_type == 'hard') %>%
  left_join(final.data.df, by = c('id' = 'Id')) %>%
  mutate(analyst = ifelse(analyst == 1, id, NA),
         engineer = ifelse(engineer == 1, id, NA),
         scientist = ifelse(scientist == 1, id, NA),
         junior = ifelse(junior == 1, id, NA),
         senior = ifelse(senior == 1, id, NA)) %>% 
  group_by(skill) %>%
  summarize(total_count = n(),
            ana_ids = n_distinct(analyst),
            ana_pct = ana_ids / sum(df_all$analyst),
            eng_ids = n_distinct(engineer),
            eng_pct = eng_ids / sum(df_all$engineer),
            sci_ids = n_distinct(scientist),
            sci_pct = sci_ids / sum(df_all$scientist),
            jr_ids = n_distinct(junior),
            jr_pct = jr_ids / sum(df_all$junior),
            sr_ids = n_distinct(senior),
            sr_pct = sr_ids / sum(df_all$senior))

# specify top number of skills
top_x <- 10

```

## Hard Skills For Data Roles

```{r, echo = F}
# Top Hard Skills for All Data Postings
ggplot( arrange(hs, desc(total_count))[1:top_x,], aes(x = reorder(skill, total_count), y = total_count/nrow(df_all))) +
  geom_col() +
  coord_flip() +
  labs(title = str_c('Top ', top_x, ' Technical Skills'),
       subtitle = str_c('Data Analysts/Engineers/Scientists'),
       y = "% of Job Posts",
       x = element_blank()) +
  scale_y_continuous(label = percent_format(accuracy = 1))
```

* Python is ranked #1 & R is ranked #4
* Skills vary after the top 2

## Hard Skills for Data Scientists

```{r, echo = F}
# Top Hard Skills for Data Scientists
ggplot( arrange(hs, desc(sci_ids))[1:top_x,], aes(x = reorder(skill, sci_pct), y = sci_pct)) +
  geom_col() +
  coord_flip() +
  labs(title = str_c('Top ', top_x, ' Technical Skills'),
       subtitle = str_c('Data Scientists'),
       y = "% of Job Posts",
       x = element_blank()) +
  scale_y_continuous(label = percent_format(accuracy = 1))
```

* More than half of job posts mention Python, machine learning, or R

## Hard Skills for Data Analysts

```{r, echo = F}
# Top Hard Skills for Data Analysts
ggplot( arrange(hs, desc(ana_ids))[1:top_x,], aes(x = reorder(skill, ana_pct), y = ana_pct)) +
  geom_col() +
  coord_flip() +
  labs(title = str_c('Top ', top_x, ' Technical Skills'),
       subtitle = str_c('Data Analysts'),
       y = "% of Job Posts",
       x = element_blank()) +
  scale_y_continuous(label = percent_format(accuracy = 1))
```

* SQL seems to be the most desired skill by far

## Hard Skills for Data Engineers

```{r, echo = F}
# Top Hard Skills for Data Engineers
ggplot( arrange(hs, desc(eng_ids))[1:top_x,], aes(x = reorder(skill, eng_pct), y = eng_pct)) +
  geom_col() +
  coord_flip() +
  labs(title = str_c('Top ', top_x, ' Technical Skills'),
       subtitle = str_c('Data Engineers'),
       y = "% of Job Posts",
       x = element_blank()) +
  scale_y_continuous(label = percent_format(accuracy = 1))

```

* Python and SQL are top skills
* R isn't in the top 10

## Hard Skills for Junior Data Scientists
  
```{r, echo = F}  
hs_jr_base <- filter(skills, skill_type == 'hard') %>%
  inner_join(filter(final.data.df, junior == 1 & scientist == 1), by = c('id' = 'Id')) 
hs_jr <-  group_by(hs_jr_base, skill) %>%
  summarize(total_count = n())
hs_jr_denom <- n_distinct(hs_jr_base$id)

# Top Hard Skills for Junior Data Scientists
ggplot( arrange(hs_jr, desc(total_count))[1:top_x,], aes(x = reorder(skill, total_count), y = total_count/hs_jr_denom)) +
  geom_col() +
  coord_flip() +
  labs(title = str_c('Top ', top_x, ' Technical Skills'),
       subtitle = str_c('Junior Data Scientists'),
       y = "% of Job Posts",
       x = element_blank()) +
  scale_y_continuous(label = percent_format(accuracy = 1))
```

* Top skills for junior data scientists are similar to data science in general
* Tableau #4 shows the value of visualizations

## Hard Skills for Senior Data Scientists

```{r, echo = F}  
hs_sr_base <- filter(skills, skill_type == 'hard') %>%
  inner_join(filter(final.data.df, senior == 1 & scientist == 1), by = c('id' = 'Id')) 
hs_sr <- group_by(hs_sr_base, skill) %>%
  summarize(total_count = n())
hs_sr_denom <- n_distinct(hs_sr_base$id)

# Top Hard Skills for Senior Data Scientists
ggplot( arrange(hs_sr, desc(total_count))[1:top_x,], aes(x = reorder(skill, total_count), y = total_count/hs_sr_denom)) +
  geom_col() +
  coord_flip() +
  labs(title = str_c('Top ', top_x, ' Technical Skills'),
       subtitle = str_c('Senior Data Scientists'),
       y = "% of Job Posts",
       x = element_blank()) +
  scale_y_continuous(label = percent_format(accuracy = 1))
sci_industry <- filter(df_all, scientist == 1 & Company_Industry != '') %>%
  group_by(Company_Industry) %>%
  summarize(postings = n()) %>%
  arrange(desc(postings))
```

* Top skills for senior data scientists are Python, Machine Learning, R, and SQL

## Job Demand for Skill Level

```{r, echo = F}
jrs <- filter(final.data.df, junior == 1) %>%
  select(Id, Analyst = analyst, Engineer = engineer, Scientist = scientist) %>%
  gather(position, count, -Id)

jrs$level <- 'Junior'

srs <- filter(final.data.df, senior == 1) %>%
  select(Id, Analyst = analyst, Engineer = engineer, Scientist = scientist) %>%
  gather(position, count, -Id)

srs$level <- 'Senior'

pos_and_role <- bind_rows(jrs, srs) %>%
  group_by(level, position) %>%
  summarize(count = sum(count))

ggplot(pos_and_role, aes(x = position, y = count, fill = level)) +
  geom_col(position = 'fill') +
  theme_bw() +
  scale_y_continuous(label = percent_format(accuracy = 1)) +
  scale_fill_manual(values = c('lightskyblue3', 'royalblue4')) +
  labs(x = element_blank(), 
       y = element_blank(),
       title = 'Distribution of Specified Levels')
```

* High demand for senior roles

## Hard Skills by Industry

```{r, echo = F}
# Top Company Industries Seeking Data Scientists
ggplot(sci_industry[1:10,], aes(x = reorder(Company_Industry, postings), y = postings / sum(sci_industry$postings))) +
  geom_col() +
  coord_flip() +
  labs(title = 'Top 10 Company Industries',
       subtitle = str_c('Data Scientist Posts'),
       y = "% of Job Posts",
       x = element_blank()) +
  scale_y_continuous(label = percent_format(accuracy = 1))
```

* Consulting and Business Services - optimizing businesses
* Internet and Software - leverage the data they have


## Word Cloud

```{r}
# WordCLoud map for the soft and hard skillset that high rating/star companies are 
# looking for in engineer vs analyst/scientist Position: 
df.stars.5 <- df_all %>%
  filter(No_of_Stars ==5  ) %>%
  select(job_id, Queried_Salary,   Company_Industry, analyst, engineer, scientist , junior, senior ) %>%
  inner_join(skills, by = c( 'job_id' = 'id'))

df.stars.5.engg <- df.stars.5 %>% 
  filter ( engineer ==1) %>%
  group_by(skill) %>%
  summarize(total_count = n())

df.stars.5.ana.sci <- df.stars.5 %>% 
  filter ( analyst + scientist > 0 ) %>%
  group_by(skill) %>%
  summarize(total_count = n())


set.seed(1234)
wordcloud(words = df.stars.5.engg$skill, freq = df.stars.5.engg$total_count, min.freq = 1,
          max.words=100, random.order=FALSE, rot.per=0.10,
          colors=brewer.pal(8, "Dark2"))

wordcloud(words = df.stars.5.ana.sci$skill, freq = df.stars.5.ana.sci$total_count, min.freq = 1,
          max.words=100, random.order=FALSE, rot.per=0.10, 
          colors=brewer.pal(8, "Dark2"))

# Salary Range by titles given by high rating/star companies:
df.stars.5.Salary <- df.stars.5 %>% 
  group_by(Queried_Salary) %>%
  summarize(total_count = n(),
            ana_total = sum(analyst),
            eng_totals = sum(engineer),
            sci_total = sum(scientist),
            jr_total = sum(junior),
            sr_total = sum(senior))

kable(df.stars.5.Salary)
# ==> We can see from above no junior level roles; No Engineer roles with greater then 
#     160,000 USD
```

```{r, warning = FALSE}
#Statewise Job posting for Data Science Jobs: 
df.states <- df_all %>% 
  select(job_id, Location ) %>%
  group_by(Location) %>%
  summarize(total_count = n())

all_states <- map_data("state")

df.states$region <- stateFromLower(df.states$Location)
Total <- merge(all_states, df.states, by="region")

Total <- Total[Total$region!="REMOTE",]

p <- ggplot()
p <- p + geom_polygon(data=Total, aes(x=long, y=lat, group = group, fill=Total$total_count),colour="white"
      ) + scale_fill_continuous(low = "#56B4E9", high = "#0072B2", guide="colorbar")

p
```