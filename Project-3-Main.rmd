---
title: "Data607-Major Assignment-Project3-Most Valued Data Science Skills"
author: "Leo Yi / David Blumensteil / Manolis Manoli / Vinayak Kamath"
date: "3/11/2020"
output:
  html_document:
    highlight: pygments
    theme: cerulean
    toc: TRUE
    toc_depth: 3    
    toc_float:
      collapsed: true
      smooth_scroll: true
      number_sections: true    
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(knitr)
library(tidyr)
library(Rmisc)
library(dplyr)
library(ggplot2)
library(scales)
library(stats)
library(grid)
#install.packages("wordcloud")
library("wordcloud")
#install.packages("RColorBrewer")
library("RColorBrewer")
library(maps)

stateFromLower <-function(x) {
   #read 52 state codes into local variable [includes DC (Washington D.C. and PR (Puerto Rico)]
  st.codes<-data.frame(
                      state=as.factor(c("AK", "AL", "AR", "AZ", "CA", "CO", "CT", "DC", "DE", "FL", "GA",
                                         "HI", "IA", "ID", "IL", "IN", "KS", "KY", "LA", "MA", "MD", "ME",
                                         "MI", "MN", "MO", "MS",  "MT", "NC", "ND", "NE", "NH", "NJ", "NM",
                                         "NV", "NY", "OH", "OK", "OR", "PA", "PR", "RI", "SC", "SD", "TN",
                                         "TX", "UT", "VA", "VT", "WA", "WI", "WV", "WY")),
                      full=as.factor(c("alaska","alabama","arkansas","arizona","california","colorado",
                                       "connecticut","district of columbia","delaware","florida","georgia",
                                       "hawaii","iowa","idaho","illinois","indiana","kansas","kentucky",
                                       "louisiana","massachusetts","maryland","maine","michigan","minnesota",
                                       "missouri","mississippi","montana","north carolina","north dakota",
                                       "nebraska","new hampshire","new jersey","new mexico","nevada",
                                       "new york","ohio","oklahoma","oregon","pennsylvania","puerto rico",
                                       "rhode island","south carolina","south dakota","tennessee","texas",
                                       "utah","virginia","vermont","washington","wisconsin",
                                       "west virginia","wyoming"))
                       )
     #create an nx1 data.frame of state codes from source column
  st.x<-data.frame(state=x)
     #match source codes with codes from 'st.codes' local variable and use to return the full state name
  refac.x<-st.codes$full[match(st.x$state,st.codes$state)]
     #return the full state names in the same order in which they appeared in the original source
  return(refac.x)
 
}

```

### Import

```{r}
#Loads the dataset
df_raw <- read.csv("https://raw.githubusercontent.com/davidblumenstiel/data/master/indeed_job_dataset.csv",stringsAsFactors = FALSE)

#Create working df object
df <- df_raw
```

### Soft Skills

```{r}
#keywords as 'keywords'
keywords<-unname(unlist(read.csv("https://raw.githubusercontent.com/chilleundso/DATA607/master/Project3/softskills.csv", stringsAsFactors = FALSE)))

#Iniates new columns for each keyword; also makes list index list
df[keywords] <- NA
keywordColIndex <- seq(length(df)-length(keywords)+1,length(df),1)

#Will determine if contains keywords; occurs (1), or doesnt occur(0)
#Coerces multiple occurances to 1
i = 0
for (desc in df$Description) {
  i = i + 1
  df[i,keywordColIndex] <-(as.integer(str_detect(desc,fixed(keywords, ignore_case = TRUE))))
}

#Gets rid of the descriptions
df$Description <- NULL

#Gather soft skills
df2 <- df[,c(1, 44:ncol(df))] %>%
  gather(skill, flag, -X) %>%
  filter(flag == 1) %>%
  select(id = X, skill) %>%
  mutate(skill_type = 'soft')
```

```{r}
#Gather soft skills
df2 <- df[,c(1, 44:ncol(df))] %>%
  gather(skill, flag, -X) %>%
  filter(flag == 1) %>%
  select(id = X, skill) %>%
  mutate(skill_type = 'soft')
```


### Hard Skills

```{r}
# List all hard skills and how often they were listed in a separate dataframe
for (i in 1:nrow(df_raw)) {
  slist <- str_extract_all(df_raw$Skill[i], "'.+?'")
  temp_df <- data.frame(skill = slist[[1]])
  if (nrow(temp_df) > 0) {
    temp_df$id <- i - 1
    temp_df$skill <- as.character(temp_df$skill)
    temp_df <- select(temp_df, id, skill)
    if (i == 1) {
      sdf <- temp_df
    } else {
      sdf <- bind_rows(sdf, temp_df)
    }
  }
}

# Remove quotes and trim whitespace
sdf$skill <- str_replace_all(sdf$skill, "'", "")
sdf$skill <- str_replace_all(sdf$skill, '"', "")
sdf$skill <- str_trim(sdf$skill)
sdf$skill_type <- 'hard'

# Combine skills
skills <- bind_rows(df2, sdf)
```


### Job Title

```{r, warning = FALSE}
df <- df_raw
job.indeed.df  <- df %>%
  select(c(Id=X, (Job_Title)))

# Pattern Building:
pattern.analyst <- c('analyst','statistician','analysis','analytics')
pattern.engineer <- c('engineer', 'engg', 'technician','technologist','designer','architect')
pattern.scientist <- c('scientist','doctor','dr.')
pattern.junior <- c('junior','jr', 'entry','internship','jr.')
pattern.senior <- c('senior', 'sr','experienced','sr.')

# Intermedaite Data Frame for Titlles:
final.data.df <- data.frame(Id=integer(nrow(job.indeed.df)), Job_Title=character(nrow(job.indeed.df))
                            , analyst=integer(nrow(job.indeed.df)) ,engineer=integer(nrow(job.indeed.df)),scientist=integer(nrow(job.indeed.df))
                            , junior=integer(nrow(job.indeed.df)),senior=integer(nrow(job.indeed.df)))
final.data.df$Id <-   job.indeed.df$Id
final.data.df$Job_Title <- as.character( as.character( job.indeed.df$Job_Title) )

# Working on the counts:
for (i in 1: nrow(job.indeed.df)) {
  final.data.df$analyst[i] <- if(grepl(paste(pattern.analyst,collapse="|"), job.indeed.df$Job_Title[i], ignore.case = TRUE) )  1 else 0
  final.data.df$engineer[i] <- if(grepl(paste(pattern.engineer,collapse="|"), job.indeed.df$Job_Title[i], ignore.case = TRUE) )  1 else 0
  final.data.df$scientist[i] <- if(grepl(paste(pattern.scientist,collapse="|"), job.indeed.df$Job_Title[i], ignore.case = TRUE) )  1 else 0
  final.data.df$junior[i] <- if(grepl(paste(pattern.junior,collapse="|"), job.indeed.df$Job_Title[i], ignore.case = TRUE) )  1 else 0
  final.data.df$senior[i] <- if(grepl(paste(pattern.senior,collapse="|"), job.indeed.df$Job_Title[i], ignore.case = TRUE) )  1 else 0
}


# Add job title flags to original dataframe
# Merging with main Analysis Data Frame:
df_all <- left_join(df_raw[,1:16], final.data.df[,-2], by = c('X' = 'Id'))
names(df_all)[1] <- 'job_id'




# hard skills dataframe for visualizations
hs <- filter(skills, skill_type == 'hard') %>%
  left_join(final.data.df, by = c('id' = 'Id')) %>%
  mutate(analyst = ifelse(analyst == 1, id, NA),
         engineer = ifelse(engineer == 1, id, NA),
         scientist = ifelse(scientist == 1, id, NA),
         junior = ifelse(junior == 1, id, NA),
         senior = ifelse(senior == 1, id, NA)) %>% 
  dplyr::group_by(skill) %>%
  dplyr::summarize(total_count = n(),
            ana_ids = n_distinct(analyst),
            ana_pct = ana_ids / sum(df_all$analyst),
            eng_ids = n_distinct(engineer),
            eng_pct = eng_ids / sum(df_all$engineer),
            sci_ids = n_distinct(scientist),
            sci_pct = sci_ids / sum(df_all$scientist),
            jr_ids = n_distinct(junior),
            jr_pct = jr_ids / sum(df_all$junior),
            sr_ids = n_distinct(senior),
            sr_pct = sr_ids / sum(df_all$senior))

# specify top number of skills
top_x <- 20

# Top Hard Skills for All Data Postings
ggplot( arrange(hs, desc(total_count))[1:top_x,], aes(x = reorder(skill, total_count), y = total_count/nrow(df_all))) +
  geom_col() +
  coord_flip() +
  labs(title = str_c('Top ', top_x, ' Technical Skills'),
       subtitle = str_c('Data Analysts/Engineers/Scientists'),
       y = "% of Job Posts",
       x = element_blank()) +
  scale_y_continuous(label = percent_format(accuracy = 1))


# Top Hard Skills for Data Scientists
ggplot( arrange(hs, desc(total_count))[1:top_x,], aes(x = reorder(skill, sci_pct), y = sci_pct)) +
  geom_col() +
  coord_flip() +
  labs(title = str_c('Top ', top_x, ' Technical Skills'),
       subtitle = str_c('Data Scientists'),
       y = "% of Job Posts",
       x = element_blank()) +
  scale_y_continuous(label = percent_format(accuracy = 1))

# Top Hard Skills for Data Analysts
ggplot( arrange(hs, desc(total_count))[1:top_x,], aes(x = reorder(skill, ana_pct), y = ana_pct)) +
  geom_col() +
  coord_flip() +
  labs(title = str_c('Top ', top_x, ' Technical Skills'),
       subtitle = str_c('Data Analysts'),
       y = "% of Job Posts",
       x = element_blank()) +
  scale_y_continuous(label = percent_format(accuracy = 1))

# Top Hard Skills for Data Engineers
ggplot( arrange(hs, desc(total_count))[1:top_x,], aes(x = reorder(skill, eng_pct), y = eng_pct)) +
  geom_col() +
  coord_flip() +
  labs(title = str_c('Top ', top_x, ' Technical Skills'),
       subtitle = str_c('Data Engineers'),
       y = "% of Job Posts",
       x = element_blank()) +
  scale_y_continuous(label = percent_format(accuracy = 1))
  
hs_jr_base <- filter(skills, skill_type == 'hard') %>%
  inner_join(filter(final.data.df, junior == 1 & scientist == 1), by = c('id' = 'Id')) 
hs_jr <-  group_by(hs_jr_base, skill) %>%
  dplyr::summarize(total_count = n())
hs_jr_denom <- n_distinct(hs_jr_base$id)

# Top Hard Skills for Junior Data Scientists
ggplot( arrange(hs_jr, desc(total_count))[1:top_x,], aes(x = reorder(skill, total_count), y = total_count/hs_jr_denom)) +
  geom_col() +
  coord_flip() +
  labs(title = str_c('Top ', top_x, ' Technical Skills'),
       subtitle = str_c('Junior Data Scientists'),
       y = "% of Job Posts",
       x = element_blank()) +
  scale_y_continuous(label = percent_format(accuracy = 1))
  
hs_sr_base <- filter(skills, skill_type == 'hard') %>%
  inner_join(filter(final.data.df, senior == 1 & scientist == 1), by = c('id' = 'Id')) 
hs_sr <- group_by(hs_sr_base, skill) %>%
  dplyr::summarize(total_count = n())
hs_sr_denom <- n_distinct(hs_sr_base$id)

# Top Hard Skills for Senior Data Scientists
ggplot( arrange(hs_sr, desc(total_count))[1:top_x,], aes(x = reorder(skill, total_count), y = total_count/hs_sr_denom)) +
  geom_col() +
  coord_flip() +
  labs(title = str_c('Top ', top_x, ' Technical Skills'),
       subtitle = str_c('Senior Data Scientists'),
       y = "% of Job Posts",
       x = element_blank()) +
  scale_y_continuous(label = percent_format(accuracy = 1))
sci_industry <- filter(df_all, scientist == 1 & Company_Industry != '') %>%
  dplyr::group_by(Company_Industry) %>%
  dplyr::summarize(postings = n()) %>%
  arrange(desc(postings))

# Top Company Industries Seeking Data Scientists
ggplot(sci_industry[1:10,], aes(x = reorder(Company_Industry, postings), y = postings / sum(sci_industry$postings))) +
  geom_col() +
  coord_flip() +
  labs(title = 'Top 10 Company Industries',
       subtitle = str_c('Data Scientist Posts'),
       y = "% of Job Posts",
       x = element_blank()) +
  scale_y_continuous(label = percent_format(accuracy = 1))


# WordCLoud map for the soft and hard skillset that high rating/star companies are 
# looking for in engineer vs analyst/scientist Position: 
df.stars.5 <- df_all %>%
  filter(No_of_Stars ==5  ) %>%
  select(job_id, Queried_Salary,   Company_Industry, analyst, engineer, scientist , junior, senior ) %>%
  inner_join(skills, by = c( 'job_id' = 'id'))

df.stars.5.engg <- df.stars.5 %>% 
  filter ( engineer ==1) %>%
  group_by(skill) %>%
  summarize(total_count = n())

df.stars.5.ana.sci <- df.stars.5 %>% 
  filter ( analyst + scientist > 0 ) %>%
  group_by(skill) %>%
  summarize(total_count = n())


set.seed(1234)
wordcloud(words = df.stars.5.engg$skill, freq = df.stars.5.engg$total_count, min.freq = 1,
          max.words=100, random.order=FALSE, rot.per=0.10,
          colors=brewer.pal(8, "Dark2"))

wordcloud(words = df.stars.5.ana.sci$skill, freq = df.stars.5.ana.sci$total_count, min.freq = 1,
          max.words=100, random.order=FALSE, rot.per=0.10, 
          colors=brewer.pal(8, "Dark2"))

# Salary Range by titles given by high rating/star companies:
df.stars.5.Salary <- df.stars.5 %>% 
  group_by(Queried_Salary) %>%
  summarize(total_count = n(),
            ana_total = sum(analyst),
            eng_totals = sum(engineer),
            sci_total = sum(scientist),
            jr_total = sum(junior),
            sr_total = sum(senior))

kable(df.stars.5.Salary)
# ==> We can see from above no junior level roles; No Engineer roles with greater then 
#     160,000 USD
```

```{r, warning = FALSE}
#Statewise Job posting for Data Science Jobs: 
df.states <- df_all %>% 
  select(job_id, Location ) %>%
  group_by(Location) %>%
  summarize(total_count = n())

all_states <- map_data("state")

df.states$region <- stateFromLower(df.states$Location)
Total <- merge(all_states, df.states, by="region")

Total <- Total[Total$region!="REMOTE",]

p <- ggplot()
p <- p + geom_polygon(data=Total, aes(x=long, y=lat, group = group, fill=Total$total_count),colour="white"
      ) + scale_fill_continuous(low = "#56B4E9", high = "#0072B2", guide="colorbar")

p
```
## Finding correlations between technical skills and salary
### First, we need to select and arrange the data we want

```{r}
#Creates a hard-skill and salary, and job type dataset
Skill_Pay <- sdf[1:2]
Skill_Pay[c("Salary","Job_Type")] <- NA

#Populates the salary and job type columns from the raw dataset
for (i in Skill_Pay$id) {
  Skill_Pay$Salary[Skill_Pay$id == i] <- df_raw$Queried_Salary[df_raw$X == i]
  Skill_Pay$Job_Type[Skill_Pay$id == i] <- df_raw$Job_Type[df_raw$X == i]
  }

#Going to focus on only data_science-type jobs
Skill_PayDS <- filter(Skill_Pay,Job_Type == 'data_scientist')

#Changes the 'skill' column to a factor type
Skill_PayDS$skill <- as.factor(Skill_PayDS$skill)

#Filters it to skills mentioned
mentions <- 200
stab = table(Skill_PayDS$skill)
Skill_PayDS <- Skill_PayDS[Skill_PayDS$skill %in% names(stab)[stab >= mentions],]

#Drops the now un-used factors from skills
Skill_PayDS <- droplevels(Skill_PayDS)

#Factors and re-orders Salary
Pay_Grades <- c("<80000", "80000-99999", "100000-119999", "120000-139999", "140000-159999",">160000")
Skill_PayDS$Salary <- factor(Skill_PayDS$Salary, levels = Pay_Grades)

#Makes a dataframe of Skills vs Salary
PayTable<- table(Skill_PayDS$skill ,Skill_PayDS$Salary)
PayTable

#Gets a total count for the number of jobs by Salary: Job_Totals
q = 0
Job_Totals <- NA
for (i in Pay_Grades) {
  q = q + 1
  Job_Totals[q] <- nrow(subset(df_raw, df_raw$Queried_Salary == i & df_raw$Job_Type == "data_scientist"))
}

Job_Totals
PayTable

```

### What types of skills do each pay-grade tend to mention?
```{r}
#Specify the significance level
sig <- 0.05


#Loops through each skill
j = 0
k = 0

plist <- NA
SigSkills <- NA
while (j < nrow(PayTable)) {
  j = j + 1
  
  
  i = 0
  
  unmentioned <- NA
  
  #Loops through the elemenents of each skill, and builds a vector of the number of jobs for which a skill-salary combo wasn't   mentioned: unmentioned
  while (i < ncol(PayTable)) {
    i = i + 1
    unmentioned[i] <- Job_Totals[i] - PayTable[j,i]
    
  }

  #Performed a chi-squared tests for by each skill by paygrade to determine skills mentioned with significant relationship
  #Saves the skills with significant relationships to a list of names and their p-values to a seperate list
  
  
  if (chisq.test(cbind(unmentioned,PayTable[j,]))$p.value < sig) {
    k = k + 1
    plist[k] <- chisq.test(cbind(unmentioned,PayTable[j,]))$p.value
    SigSkills[k] <- names(PayTable[,1])[j]
    
    }
  
}
```

### Proportion plots for skills vs salary

##### The plots below show the proportions of posts that mention a skill for each salary range.  The horizontal bar would be the expected proportion if there was no difference in the proportion of mentions according to the salary range.  The plots shown are only those for which there were over 200 skill mentions p > 0.05 (as determined by chi squared tests).  There are several interesting findings below, and if one is interested in knowing which skills seem to correlate with the highest paying jobs: C/C++, Hadoop, Hive, Java, NLP, Scala, Spark, and TensorFlow.

```{r}
i = 0
skillplots <- list()
while (i < length(SigSkills)) {
  i = i + 1
  plottemp <- as.data.frame(PayTable[SigSkills[i],]/Job_Totals)
  print (ggplot(plottemp, aes(x = plottemp[,1], y = rownames(plottemp), fill = rownames(plottemp))) +
    geom_bar(stat = "identity", width=0.9) +
    scale_y_discrete(limits=rownames(plottemp)) +
    geom_vline(xintercept = sum(PayTable[SigSkills[i],])/sum(Job_Totals)) +
    scale_fill_brewer(palette=1, type = "qual") +
    xlab("Proportion") +
    ylab("Salary Range") +
    ggtitle(paste("Proportion of Job Postings that Mention",SigSkills[i],";  p = ",round(plist[i], digits = 6))) +
    labs(fill = "Salary Range")+
    theme(axis.text.x = element_text(angle = 15)) +
    coord_flip())
  
  
}  

```
